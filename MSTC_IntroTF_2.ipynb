{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MSTC_IntroTF_2.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "cFntciKlhH1C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#  From <font color='organge'>\"manual\"</font> learning to <font color='brown'>\"machine\"</font> learning\n",
        "## A Simple linear classifier in [TensorFlow](https://www.tensorflow.org/) (logistic regression)\n",
        "\n",
        "<img src=\" https://www.skylinelabs.in/blog/images/tensorflow.jpg\">\n",
        "\n",
        "\n",
        "* <font size=5 color='green'>[MSTC](http://mstc.ssr.upm.es/big-data-track) seminar on Deep Learning & Tensorflow</font>"
      ]
    },
    {
      "metadata": {
        "id": "a79ndaP9hH1G",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sS2gcP7GhH1R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generate two-class artificial data using $numpy$"
      ]
    },
    {
      "metadata": {
        "id": "SbQcje4XhH1T",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Number of data per-class\n",
        "Ndata_class=100\n",
        "\n",
        "group1 = np.random.multivariate_normal([-4, -4], 20*np.identity(2), size=Ndata_class)\n",
        "group2 = np.random.multivariate_normal([4, 4], 20*np.identity(2), size=Ndata_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EcGshEKJhH1a",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Plot artificial data\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.scatter(group1.T[0][:],group1.T[1][:])\n",
        "plt.scatter(group2.T[0][:],group2.T[1][:],color='g')\n",
        "plt.xlabel('x1',fontsize=18)\n",
        "plt.ylabel('x2',fontsize=18)\n",
        "plt.title('Artificial Data',fontsize=18)\n",
        "plt.grid(color='k', linestyle='--')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hpk6OlXUhH1m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### \"manual\" linear discrimination\n",
        "* x2= w1 * x1 + b\n",
        "<br>or\n",
        "* x2 - w1*x1 - b = 0"
      ]
    },
    {
      "metadata": {
        "id": "R4Ei_4MZhH1o",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x1 = np.arange(-15, 15, 0.1)\n",
        "\n",
        "b=0.0\n",
        "w1=-1.0\n",
        "#w1=1.0\n",
        "\n",
        "x2= w1 * x1 + b "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_xLan16nhH1t",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Plot linear discrimination\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.scatter(group1.T[0][:],group1.T[1][:])\n",
        "plt.scatter(group2.T[0][:],group2.T[1][:],color='g')\n",
        "plt.plot(x1,x2,color='r')\n",
        "plt.xlabel('x1',fontsize=18)\n",
        "plt.ylabel('x2',fontsize=18)\n",
        "plt.title('Linear Discrimination',fontsize=18)\n",
        "plt.grid(color='k', linestyle='--')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MkXt37LNhH12",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Classification based on the distance to the line\n",
        "\n",
        "* x2 - w1*x1 - b > 0  'green' points\n",
        "* x2 - w1*x1 - b < 0  'blue' points\n"
      ]
    },
    {
      "metadata": {
        "id": "xmhS_LkPhH14",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_X = np.vstack((group1, group2))\n",
        "pred= train_X.T[1] - w1 * train_X.T[0] - b \n",
        "\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.plot(pred)\n",
        "plt.xlabel('x1',fontsize=18)\n",
        "plt.ylabel('x2',fontsize=18)\n",
        "plt.title('Classification: < 0 \\'blue\\' > 0 \\'green\\' ',fontsize=18)\n",
        "plt.grid(color='k', linestyle='--')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jvyg0F60hH2D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### let's make these values \"probabilities\" using the $sigmoid$ function"
      ]
    },
    {
      "metadata": {
        "id": "VBU58W5ihH2F",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x = np.arange(-10, 11)\n",
        "plt.title('Sigmoid : logistic function',fontsize=18)\n",
        "plt.xlabel('$x$')\n",
        "plt.ylabel('$p(X)=1/(1+exp(-x))$',fontsize=16)\n",
        "plt.plot(x, (1/(1+np.exp(-x))));\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O2oyzikyhH2V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####     Prediction using the $logistic$ or $sigmoid$ function \n",
        "* $p(X) = 1/(1 + \\exp(x))$, taking values between $0$ and $1$.\n",
        "\n",
        "* $p(X)$ represents the probability that the point $X$ should be labelled \"green\".\n"
      ]
    },
    {
      "metadata": {
        "id": "wrCgCeWBhH2X",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(9,6))\n",
        "plt.plot((1/(1+np.exp(-pred))))\n",
        "plt.ylim(-0.02, 1.02)\n",
        "\n",
        "plt.title('Class-probabilities',fontsize=18)\n",
        "plt.xlabel('$pred$',fontsize=16)\n",
        "plt.ylabel('$p(X)=1/(1+exp(-pred))$',fontsize=16)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vqi9-4lnhH2k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Classification cost function will be the cross-entropy, $$-\\sum_{i=1}^n l(X_i) \\log(p(X_i)) + (1-l(X_i))\\log(1-p(X_i)),$$ where $l(X_i)$ is the label of $X_i$ (which is $0$ for 'blue' or $1$ for 'green').\n"
      ]
    },
    {
      "metadata": {
        "id": "xBjPtk2fhH2l",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_labels = np.array([0.0] * Ndata_class + [1.0] * Ndata_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "thkvoCpfhH2s",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Cost function is cross-entropy\n",
        "pred_prob=(1/(1+np.exp(-pred)))\n",
        "cost = -sum((train_labels) * np.log(pred_prob + 1e-10) + (1-train_labels) * np.log(1-pred_prob + 1e-10))\n",
        "\n",
        "print(\"cross-entropy: {}\".format(cost))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ovF9CTaIhH21",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "Accuracy=np.sum((pred_prob>0.5).astype(int) == train_labels)/(len(pred_prob)*1.0)\n",
        "\n",
        "print(\"Classification Accuracy = \",Accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l9iUnBLChH28",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using TensorFlow for:\n",
        "\n",
        "- ### Feeding data into a $given$ linear classifier with sigmoid output"
      ]
    },
    {
      "metadata": {
        "id": "sXg5nqW9hH2_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### GRAPH DEFINITION\n",
        "\n",
        "# PLACEHOLDERS:\n",
        "# Inputs are now two-dimensional and come with labels \"blue\" or \"green\" (represented by 0 or 1)\n",
        "X = tf.placeholder(\"float\", shape=[None, 2])\n",
        "labels = tf.placeholder(\"float\", shape=[None])\n",
        "\n",
        "\n",
        "# Set model weights and bias as before\n",
        "#W = tf.Variable(tf.ones([2, 1], \"float\"), name=\"weight\")\n",
        "#b = tf.Variable(tf.zeros([1], \"float\"), name=\"bias\")\n",
        "\n",
        "W=tf.constant([[1.0], [1.0]],name=\"weights\")\n",
        "b=tf.constant(0.0,name=\"bias\")\n",
        "\n",
        "\n",
        "# Predictor is now the logistic function\n",
        "#pred = tf.sigmoid(tf.to_double(tf.reduce_sum(tf.matmul(X, W), axis=[1]) + b))\n",
        "pred = tf.sigmoid(tf.to_double(tf.reduce_sum(tf.matmul(X, W),1) + b))\n",
        "\n",
        "# Cost function is cross-entropy\n",
        "cost = -tf.reduce_sum(tf.to_double(labels) * tf.log(pred) + (1-tf.to_double(labels)) * tf.log(1-pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ukjgwui3hH3G",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### GRAPH EXECUTION\n",
        "\n",
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()\n",
        "#init = tf.initialize_all_variables()\n",
        "\n",
        "# We stack our two groups of 2-dimensional points\n",
        "train_X = np.vstack((group1, group2))\n",
        "\n",
        "# labels to feed them\n",
        "train_labels = np.array([0.0] * Ndata_class + [1.0] * Ndata_class)\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    sess.run(init)\n",
        "    \n",
        "    pred_out, cost_out=sess.run([pred, cost], feed_dict={X: train_X, labels: train_labels})\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9N55Adv8hH3P",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"cross-entropy: {}\".format(cost_out))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I3ysOnxThH3m",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "Accuracy=np.sum((pred_out>0.5).astype(int) == train_labels)/(len(pred_out)*1.0)\n",
        "\n",
        "print(\"Classification Accuracy = \",Accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cv-m0wbDhH3s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Now let's train!\n",
        "\n",
        "\n",
        "\n",
        "*   Both $W$ and $b$ are now <font size=4 color=green> variables</font>\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "m__uHgZ5hH3t",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Inputs are now two-dimensional and come with labels \"blue\" or \"green\" (represented by 0 or 1)\n",
        "X = tf.placeholder(\"float\", shape=[None, 2])\n",
        "labels = tf.placeholder(\"float\", shape=[None])\n",
        "\n",
        "# Set model weights and bias as before\n",
        "W = tf.Variable(tf.zeros([2, 1], \"float\"), name=\"weight\")\n",
        "b = tf.Variable(tf.zeros([1], \"float\"), name=\"bias\")\n",
        "\n",
        "# Predictor is now the logistic function\n",
        "#pred = tf.sigmoid(tf.to_double(tf.reduce_sum(tf.matmul(X, W), axis=[1]) + b))\n",
        "pred = tf.sigmoid(tf.to_double(tf.reduce_sum(tf.matmul(X, W),1) + b))\n",
        "\n",
        "\n",
        "# Cost function is cross-entropy\n",
        "cost = -tf.reduce_sum(tf.to_double(labels) * tf.log(pred) + (1-tf.to_double(labels)) * tf.log(1-pred))\n",
        "\n",
        "# Gradient descent\n",
        "learning_rate = 0.001\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
        "\n",
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()\n",
        "#init = tf.initialize_all_variables()\n",
        "\n",
        "# We stack our two groups of 2-dimensional points\n",
        "train_X = np.vstack((group1, group2))\n",
        "\n",
        "# labels to feed them\n",
        "train_labels = np.array([0.0] * Ndata_class + [1.0] * Ndata_class)\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    # We can Run the optimization algorithm several times\n",
        "    for i in range(10):\n",
        "        cost_out,W_out,b_out,pred_out,_=sess.run([cost, W,b, pred, optimizer], feed_dict={X: train_X, labels: train_labels})\n",
        "        print(\"\\n***** Epoch : %d \\n Cost= %s \"%(i,cost_out))\n",
        "        print(\"Weights= \",format(W_out))\n",
        "        print(\"bias= \",format(b_out))\n",
        "        \n",
        "        Accuracy=np.sum((pred_out>0.5).astype(int) == train_labels)/(len(pred_out)*1.0)\n",
        "\n",
        "        print(\"Classification Accuracy = \",Accuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WQfPDBCRhH4G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Now we train using batches\n"
      ]
    },
    {
      "metadata": {
        "id": "Bpe9JNc-hH4K",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.cm as cm\n",
        "import seaborn as sns\n",
        "\n",
        "n_samples=Ndata_class*2\n",
        "batch_size=40\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    # We stack our two groups of 2-dimensional points and label them 0 and 1 respectively\n",
        "    train_X = np.vstack((group1, group2))\n",
        "\n",
        "    # labels to feed them\n",
        "    train_labels = np.array([0.0] * Ndata_class + [1.0] * Ndata_class)\n",
        "\n",
        "\n",
        "    sess.run(init)\n",
        "\n",
        "    # Run the optimization algorithm 1000 times\n",
        "    for i in range(1000):\n",
        "        # Select random minibatch\n",
        "        indices = np.random.choice(n_samples, batch_size)\n",
        "        X_batch, labels_batch = train_X[indices], train_labels[indices]\n",
        "        sess.run(optimizer, feed_dict={X: X_batch, labels: labels_batch})\n",
        "\n",
        "        \n",
        "    # Plot the predictions: the values of p\n",
        "    Xmin = np.min(train_X)-1\n",
        "    Xmax = np.max(train_X)+1\n",
        "    x = np.arange(Xmin, Xmax, 0.1)\n",
        "    y = np.arange(Xmin, Xmax, 0.1)\n",
        "    \n",
        "\n",
        "    plt.scatter(group1.T[0][:],group1.T[1][:])\n",
        "    plt.scatter(group2.T[0][:],group2.T[1][:],color='g')\n",
        "    plt.xlim(Xmin, Xmax)\n",
        "    plt.ylim(Xmin, Xmax)\n",
        "    print('W = ', sess.run(W))\n",
        "    print('b = ', sess.run(b))\n",
        "    \n",
        "    xx, yy = np.meshgrid(x, y)\n",
        "    predictions = sess.run(pred, feed_dict={X: np.array((xx.ravel(), yy.ravel())).T})\n",
        "    \n",
        "    plt.title('Probability that model will label a given point \"green\"')\n",
        "    plt.contour(x, y, predictions.reshape(len(x), len(y)), cmap=cm.BuGn, levels=np.arange(0.0, 1.1, 0.1))\n",
        "    plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J0nALdxAhH4V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Logistic regression in TensorFlow\n",
        "\n",
        "https://gist.github.com/fuglede/ad04ce38e80887ddcbeb6b81e97bbfbc\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "07wEoayZhH4W",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}